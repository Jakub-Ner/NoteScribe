{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYRmRMkqJmL",
        "outputId": "ae6adf4e-aa97-403f-90d3-601af3a62bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "11_LABS_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "#@title Initial configuration\n",
        "!pip install langchain openai elevenlabs > /dev/null 2>&1\n",
        "!pip install pytesseract > /dev/null 2>&1\n",
        "!pip install pdf2image > /dev/null 2>&1\n",
        "!pip install fpdf > /dev/null 2>&1\n",
        "\n",
        "!pip install unstructured tiktoken chromadb chroma pypdf > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr > /dev/null 2>&1\n",
        "!apt-get install libtesseract-dev > /dev/null 2>&1\n",
        "!apt-get install poppler-utils > /dev/null 2>&1\n",
        "\n",
        "# Download Polish language data file\n",
        "!wget https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata > /dev/null 2>&1\n",
        "\n",
        "# Specify the Tesseract data directory\n",
        "tessdata_dir = '/usr/share/tesseract-ocr/4.00/tessdata/'\n",
        "\n",
        "# Move the downloaded language data file to the Tesseract data directory\n",
        "!mv pol.traineddata $tessdata_dir\n",
        "\n",
        "# Set TESSDATA_PREFIX environment variable\n",
        "import os\n",
        "import elevenlabs\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"OPENAI_API_KEY: \")\n",
        "elevenlabs.set_api_key(getpass(\"11_LABS_API_KEY: \")) \n",
        "\n",
        "os.environ['TESSDATA_PREFIX'] = tessdata_dir\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLZ4MdtbfNQz"
      },
      "source": [
        "## **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SB91ot3rqhd8"
      },
      "outputs": [],
      "source": [
        "# @title Convert .md -> .pdf { display-mode: \"form\" }\n",
        "!sudo apt-get install pandoc texlive-latex-base texlive-fonts-recommended texlive-extra-utils texlive-latex-extra > /dev/null 2>&1\n",
        "\n",
        "def md_to_pdf():\n",
        "  \"\"\"Converts md file into pdf.\"\"\"\n",
        "  !pandoc /content/sample_data/conversation.md -o /content/sample_data/conversation.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LeE7pxHdkn1A"
      },
      "outputs": [],
      "source": [
        "# @title Downloader { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "\n",
        "def download_conversation(text, file_path=\"/content/sample_data/conversation\"):\n",
        "  with open(f\"{file_path}.md\", \"w+\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  md_to_pdf()\n",
        "  files.download(f\"{file_path}.pdf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "AIbzkQtmfZUI",
        "outputId": "30c581dc-37de-405f-e0cf-d8e365ce6704"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "#**Hello** *World:* $\\frac{1}{2} \\times \\pi \\times r^2$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Print Markdown { display-mode: \"form\" }\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def print_md(text=r'#**Hello** *World:* $\\frac{1}{2} \\times \\pi \\times r^2$'):\n",
        "    display(Markdown(text))\n",
        "print_md()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UICnmBg-fZYB"
      },
      "outputs": [],
      "source": [
        "#@title 11Labs { display-mode: \"form\" }\n",
        "from elevenlabs import generate, play\n",
        "\n",
        "def generate_and_play(text=\"Some very long text to be read by the voice\"):\n",
        "  audio = generate(\n",
        "      text=text, \n",
        "      model='eleven_multilingual_v1'\n",
        "      )\n",
        "\n",
        "  play(audio, notebook=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyM-xo-Hq7I-"
      },
      "source": [
        "## **Agent Tools**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vKQJ5w73n2Dm"
      },
      "outputs": [],
      "source": [
        "#@title Menu View\n",
        "MENU_VIEW_ENG = \\\n",
        "\"\"\"# Welcome!\n",
        "## Settings:\n",
        " - audio (**on**/off)\n",
        " - text formatting (**.md**/.txt)\n",
        " - language\n",
        "\n",
        "## Avaliable programs:\n",
        " - compendium - university courses content scraper and personal tutor\n",
        " - img2pdf - converter for images to pdfd\n",
        "\"\"\"\n",
        "\n",
        "MENU_VIEW_PL = \\\n",
        "\"\"\"# Witaj\n",
        "## Ustawienia:\n",
        " - audio (**wł** / wył)\n",
        " - formatowanie tekstu (**.md** / .txt)\n",
        " - język\n",
        "\n",
        "## Dostępne narzędzia:\n",
        " - Compendium -  Wyszukiwarka wiedzy uniwersyteckiej i osobisty tutor\n",
        " - im2pdf - Konwerter zdjęć do pdf\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y5MKE93eqv3X"
      },
      "outputs": [],
      "source": [
        "#@title ChatConfiguration { display-mode: \"form\" }\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.tools import tool\n",
        "\n",
        "USE_CASE_LITERAL = Literal[\"menu\", \"compendium\"]\n",
        "STATE_AUDIO_LITERAL = Literal[\"on\", \"off\"]\n",
        "STATE_TEXT_LITERAL = Literal[\"md\", \"txt\"]\n",
        "\n",
        "class ChatConfigurationSingleton:\n",
        "  __instance = None\n",
        "\n",
        "  use_case: USE_CASE_LITERAL = \"menu\"\n",
        "  audio_state: STATE_AUDIO_LITERAL = \"on\"\n",
        "  text_state: STATE_TEXT_LITERAL = \"md\"\n",
        "\n",
        "  used_tokens = 0\n",
        "  total_cost = 0\n",
        "\n",
        "  def __new__(cls, *args, **kwargs):\n",
        "    if not cls.__instance:\n",
        "        cls.__instance = super().__new__(cls, *args, **kwargs)\n",
        "    return cls.__instance\n",
        "\n",
        "  def extract_inf(self, openai_cb): # BUG\n",
        "    self.used_tokens += openai_cb.total_tokens\n",
        "    self.total_cost += openai_cb.total_cost\n",
        "\n",
        "  def show(self, text):\n",
        "    if self.text_state == \"md\":\n",
        "      print_md(text)\n",
        "    else:\n",
        "      print(text)\n",
        "\n",
        "    if self.audio_state == \"on\":\n",
        "      generate_and_play(text)\n",
        "      \n",
        "\n",
        "  def run(self, run_func, text):\n",
        "    with get_openai_callback() as cb:\n",
        "      response = run_func(text)\n",
        "      self.extract_inf(cb) # BUG\n",
        "\n",
        "    self.show(response)\n",
        "\n",
        "chat_config = ChatConfigurationSingleton()\n",
        "\n",
        "\n",
        "@tool(return_direct=True)\n",
        "def set_use_case_toool(state: USE_CASE_LITERAL) -> str:\n",
        "  \"\"\"Useful at the beginning, when user knows what he want\n",
        "    @param use_case: The use case to be processed.\n",
        "      \"menu\" - back to menu\n",
        "      \"compendium\" - university courses content scraper and personal tutor\n",
        "      img2pdf\n",
        "  \"\"\"\n",
        "  chat_config.use_case = state\n",
        "  return f\"Switched to {state}\"\n",
        "\n",
        "@tool(return_direct=True)\n",
        "def set_audio_tool(state: STATE_AUDIO_LITERAL) -> str:\n",
        "  \"\"\"Useful when user want or don't want speaking responses\"\"\"\n",
        "  chat_config.audio_state = state\n",
        "  return f\"From now audio responses are turned {state}\"\n",
        "\n",
        "@tool(return_direct=True)\n",
        "def set_markdown_tool(state: STATE_TEXT_LITERAL) -> str:\n",
        "  \"\"\"Turn off or on markdown formatted responses\"\"\"\n",
        "  chat_config.text_state = state\n",
        "  return f\"From now messages are displayed using {state}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R_AU4Qlte4O"
      },
      "source": [
        "## **Compendium**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DSe_CZ-Lxb97"
      },
      "outputs": [],
      "source": [
        "courses_recources = {\n",
        "    \"Fizyka I\" : [\n",
        "      (\"pl\", \"/content/GFG-15.pdf\")   \n",
        "    ],\n",
        "    \"analiza matematyczna\": {\n",
        "        \n",
        "    }\n",
        "} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "41PBlP_F9_s3"
      },
      "outputs": [],
      "source": [
        "#@title Resource fetcher\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "import json\n",
        "\n",
        "def getLanguage(text):\n",
        "  llm = OpenAI(temperature = 0)\n",
        "\n",
        "  prompt = PromptTemplate(\n",
        "          input_variables=[\"text\"],\n",
        "          template=\"What is a language of that text: {text}? Answer in one word\",\n",
        "      )\n",
        "\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=OpenAI())\n",
        "  return llm_chain.run(text).replace(\"\\n\", \"\").replace(\":\", \"\")\n",
        "\n",
        "\n",
        "def addDataSource(name_of_course: str, pdf_path: str):\n",
        "\n",
        "  loader = UnstructuredPDFLoader(pdf_path)\n",
        "\n",
        "  data = loader.load()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=0)\n",
        "  texts = text_splitter.split_documents(data)\n",
        "\n",
        "  data_source = (getLanguage(texts[0]), pdf_path)\n",
        "\n",
        "  try:\n",
        "    with open(\"/content/embeddings.json\", \"r\") as file:\n",
        "      data = json.load(file)\n",
        "  except FileNotFoundError:\n",
        "    data = {}\n",
        "\n",
        "  if name_of_course in data:\n",
        "      data[name_of_course].append(data_source)\n",
        "  else:\n",
        "      data[name_of_course] = [data_source]\n",
        "\n",
        "\n",
        "  with open(\"/content/embeddings.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5h2RvRxAtxFj"
      },
      "outputs": [],
      "source": [
        "#@title helpers { display-mode: \"form\" }\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def get_questions(zakres, lang):\n",
        "  match lang:\n",
        "    case \"pl\" : template_questions = \"Zadaj pytania dotyczace badz zwiazane z tym zagadnieniem: {zakres}, wylistuj je i zakoncz dzialanie. Pytania:\"\n",
        "    case \"eng\" : template_questions = \"Ask question about or related to topic {zakres}. List them and end task. Questions:\" # BUG\n",
        "\n",
        "  llm_questions = ChatOpenAI(temperature=0.8, max_tokens=1000)\n",
        "  prompt_questions = PromptTemplate(input_variables=[\"zakres\"], template=template_questions)\n",
        "  chain_questions = LLMChain(llm=llm_questions,prompt=prompt_questions)\n",
        "  return chain_questions({\"zakres\":zakres}, return_only_outputs=True)['text'].split(\"\\n\")[:5] # -2\n",
        "\n",
        "\n",
        "def get_resources(nazwa_kursu):\n",
        "  lang, url = courses_recources[nazwa_kursu][0]\n",
        "\n",
        "  match lang:\n",
        "    case \"pl\": print_md(f\"Użyję {url}\")\n",
        "    case \"eng\": print_md(f\"I will use {url}\")\n",
        "\n",
        "  return lang, url\n",
        "\n",
        "\n",
        "def get_documents(url):\n",
        "  loader = PyPDFLoader(url)\n",
        "  pages = loader.load_and_split()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
        "  return text_splitter.split_documents(pages)\n",
        "\n",
        "def get_QA(summary, questions_list):\n",
        "  llm = ChatOpenAI(temperature=0.8,max_tokens=1000, model_name=\"gpt-3.5-turbo\")\n",
        "  promptTester = PromptTemplate(\n",
        "      input_variables = [\"summary\", \"QA\"],\n",
        "      template = \"\"\"Create a test to help memorize and practice the material from {summary} and {QA}. There should be multiple questions\n",
        "      The format should be:\n",
        "      [QUESTION]?\n",
        "      a) answer\n",
        "      b) answer\n",
        "      c) answer\n",
        "      d) answer\n",
        "\n",
        "      Odpowiedź:\n",
        "      \"\"\",\n",
        "  )\n",
        "\n",
        "  testerChain = LLMChain(llm=llm, prompt=promptTester, output_key=\"test\")\n",
        "  return testerChain({\"summary\":summary,\"QA\":questions_list})[\"test\"]\n",
        "\n",
        "\n",
        "def get_notes(summary, QA):\n",
        "  llm = OpenAI(temperature=0.8,max_tokens=1000, model_name=\"gpt-3.5-turbo\")\n",
        "  promptNote = PromptTemplate(\n",
        "      input_variables = [\"sumText\",\"QA\" ],\n",
        "      template = \"\"\"Connect the information from {sumText} and {QA} into a big note from which students can learn and remove breaklines.\"\"\",\n",
        "  )\n",
        "\n",
        "  noteChain = LLMChain(llm=llm,prompt=promptNote, output_key=\"summary\")\n",
        "  return noteChain({\"sumText\": summary,\"QA\": QA})[\"summary\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si1SYqMIgUi7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Apb6nnX4vH_4"
      },
      "outputs": [],
      "source": [
        "#@title Run Compendium\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain import VectorDBQA\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def ask(msg, content):\n",
        "  option = input(msg)\n",
        "  # content += f\"{msg}:{option}\"\n",
        "  return option == \"yes\" or option ==  \"tak\" or option ==  \"pewnie\" or option ==  \"sure\" \n",
        "    \n",
        "def run_compendium(nazwa_kursu, zakres, url, lang):\n",
        "  with get_openai_callback() as cb:\n",
        "    if not (url and lang):\n",
        "      lang, url = get_resources(nazwa_kursu)\n",
        "    questions_list = get_questions(zakres, lang)\n",
        "\n",
        "    for question in questions_list:\n",
        "      chat_config.show(question)\n",
        "\n",
        "    document = get_documents(url)\n",
        "    # print(f'Now you have {len(document)} documents')\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "    docsearch = Chroma.from_documents(document, embeddings)\n",
        "    chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0.7,max_tokens=1000) ,chain_type='map_reduce', retriever=docsearch.as_retriever(), return_source_documents=True)\n",
        "\n",
        "    summary = \"\"\n",
        "    for question in questions_list:\n",
        "      summary += chain({'query':f'{question} Rozwin swoja wypowiedz o jak najwiecej szczegolow'},return_only_outputs=True)['result']\n",
        "    \n",
        "    content = f\"## Podsumowanie:\\n{summary}\\n\" \n",
        "    chat_config.show(summary)\n",
        "    \n",
        "    # QA Maker\n",
        "    if ask(\"Chcesz sprawdzić swoją wiedzę?:\", content):\n",
        "      QA = get_QA(summary, questions_list)\n",
        "      content += f\"\\n## Test wiedzy:\\n{QA}\\n\" \n",
        "      chat_config.show(QA)\n",
        "\n",
        "    # Notes Maker\n",
        "    if ask(\"Chcesz notatki?:\", content):\n",
        "      notes = get_notes(summary, QA)\n",
        "      content += f\"\\n## Notatki:\\n{notes}\\n\"\n",
        "      chat_config.show(notes)\n",
        "\n",
        "    content += f\"\\n\\n*Used {chat_config.used_tokens} tokens, what cost: ${chat_config.total_cost}*\"\n",
        "    # Downloader\n",
        "    if ask(\"Chcesz pobrać:\", content):\n",
        "      download_conversation(content)\n",
        "    \n",
        "    chat_config.extract_inf(cb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOROUp0B9t1H"
      },
      "source": [
        "## **Imgs2PDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w4Uu2He990gK"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "from fpdf import FPDF\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def delete_special_characters(word):\n",
        "  for character in word:\n",
        "    if ord(character) > 127:\n",
        "      return False\n",
        "  return True\n",
        "    \n",
        "    \n",
        "def convert_images_to_searchable_pdf(pdf_path: str, return_path: str) -> None:\n",
        "    \"\"\"Extracts text from an image and saves it as pdf file to user device\"\"\"\n",
        "    images = convert_from_path(pdf_path)\n",
        "    # save FPDF() class into a variable pdf\n",
        "    pdf = FPDF()\n",
        "    for i, image in enumerate(images):\n",
        "        # Extract text from image\n",
        "        text = pytesseract.image_to_string(image, lang=\"pol\")\n",
        "        # Add a page\n",
        "        pdf.add_page()\n",
        "        \n",
        "        # set style and size of font\n",
        "        # that you want in the pdf\n",
        "        pdf.set_font(\"Arial\", size=15)\n",
        "        \n",
        "        for line in text.split('\\n'):\n",
        "            if delete_special_characters(line):\n",
        "                pdf.cell(200, 10, txt=line, ln=1, align='C')\n",
        "        \n",
        "        # save the pdf with name .pdf\n",
        "    pdf.output(return_path) \n",
        "       \n",
        "\n",
        "pdf_path = '/content/530_Krotki_wyk_ad_z_fizyki_ogolnej.pdf' #@param {type:\"string\"}\n",
        "return_path = '/content/GFG.pdf' #@param {type:\"string\"}\n",
        "# convert_images_to_searchable_pdf(pdf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMEpHl27qj4Z"
      },
      "source": [
        "# **Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "TlaKBnKPfYaV",
        "outputId": "687f7e48-e1eb-4d40-9c18-34df8ad58d85"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Welcome!\n",
              "## Settings:\n",
              " - audio (**on**/off)\n",
              " - text formatting (**.md**/.txt)\n",
              " - language\n",
              "\n",
              "## Avaliable programs:\n",
              " - compendium - university courses content scraper and personal tutor\n",
              " - img2pdf - converter for images to pdfd\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Initialize Agent\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "chat_llm = ChatOpenAI(temperature=0)\n",
        "tools = [set_use_case_toool, set_audio_tool, set_markdown_tool]\n",
        "agent = initialize_agent(tools, chat_llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, memory=memory)\n",
        "\n",
        "print_md(MENU_VIEW_ENG)\n",
        "memory.chat_memory.add_ai_message(MENU_VIEW_ENG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pSYkoUN3fYnU",
        "outputId": "ad2248ed-4888-48dd-e1d1-c2d96aac8361"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "1. What is the Boundless Distributed Alignment Search method and how does it work?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "2. How does the Boundless Distributed Alignment Search method compare to other existing alignment search methods in terms of effectiveness and efficiency?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "3. What are the advantages and disadvantages of using the Boundless Distributed Alignment Search method?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "4. Can the Boundless Distributed Alignment Search method be used for large-scale genome sequencing projects? "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "5. How does the Boundless Distributed Alignment Search method handle missing or incomplete data?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The Boundless Distributed Alignment Search (DAS) is a method used to align interpretable causal variables of a model C and fixed dimensionality linear subspaces of neural representations in a network N using gradient descent. The method works by rotating the neural representations in the network N with an orthogonal matrix such that they align with the interpretable causal variables of the model C. This alignment is learned using gradient descent. By aligning the neural representations with the model variables, DAS allows for a better understanding of the relationship between the model and the neural network. \n",
              "\n",
              "DAS is a powerful method for aligning neural network representations with interpretable causal variables, allowing for better understanding and interpretation of the model. It is a technique used to scale the alignment search of causal structure in large language models (LLMs) with billions of parameters. It is a novel and effective method that can identify the ideal set of hypotheses and search optimally for causal structure. The method works by utilizing a distributed architecture that allows for parallel processing across multiple machines, enabling efficient and scalable alignment search. It can find causal structure even when the model's task performance is low, due to factors such as suboptimal generation methods or rigid assessment metrics.\n",
              "\n",
              "In the field of natural language processing (NLP), DAS is used to align word embeddings with high-level concepts. Unlike previous methods that assumed a one-to-one mapping between a group of neurons and a high-level concept, Boundless DAS focuses on distributed alignment search, allowing multiple concepts to be aligned with the same group of neurons or vice versa. What sets Boundless DAS apart is its ability to be adapted into a head-wise alignment search, where a shared rotation matrix is added on top of the head representations of all the tokens. This method is highly effective in aligning word embeddings with high-level concepts and has been implemented in various NLP models.\n",
              "\n",
              "In summary, DAS is a method for aligning neural network representations with interpretable causal variables, allowing for better understanding and interpretation of the model. It can be used to scale the alignment search of causal structure in large language models with billions of parameters and align word embeddings with high-level concepts. The Boundless DAS method represents an important step forward in the development of interpretable AI methods, which are critical for ensuring AI safety and advancing our understanding of complex models.Unfortunately, the given portion of the document does not provide any explicit information about how the Boundless Distributed Alignment Search method compares to other existing alignment search methods in terms of effectiveness and efficiency. The text only mentions that Boundless DAS is a novel method for scaling alignment search of causal structure in large-scale learning models. It is capable of finding structure even when the model's task performance is low, and it can adapt to a head-wise alignment search. \n",
              "\n",
              "However, the text does not provide any specific information on the efficiency of Boundless DAS in comparison to other methods. It only highlights its unique features and the fact that it can find interpretable causal structure in the Alpaca model. It is possible that further information about the comparison of Boundless DAS with other methods is provided in other sections of the document or in external sources. \n",
              "\n",
              "In summary, based on the given portion of the document, it is not possible to provide a detailed answer about how the Boundless Distributed Alignment Search method compares to other existing alignment search methods in terms of effectiveness and efficiency.According to the extracted parts of the document, the Boundless Distributed Alignment Search (DAS) method has several advantages. One of the most significant advantages is its effectiveness in scaling alignment search of causal structure in Large Language Models (LLMs) to billions of parameters. This is a useful feature, as it allows the method to find causal structure even in cases where the model's task performance is low, making it possible to identify suboptimal generation methods or rigid assessment metrics. \n",
              "\n",
              "Another advantage of the Boundless DAS method is that it can be used to identify ideal sets of hypotheses and search optimally. This is because it breaks the assumption of localist representation, which is often too ideal in practice. Additionally, it specifically focuses on distributed alignment search, making it a powerful tool for analyzing LLMs and identifying causal structures.\n",
              "\n",
              "However, there are also some potential disadvantages to using the Boundless DAS method. For example, it may only find partial support for causal structure, as seen in the results of Geiger et al. Furthermore, more research needs to be done to model errors of the language model in more detail to tighten the connection between task performance and the identification of causal structure.\n",
              "\n",
              "In summary, the Boundless DAS method has several advantages, including its scalability and ability to identify ideal sets of hypotheses and search optimally. However, it also has some potential disadvantages, such as only finding partial support for causal structure and requiring more research to model errors of the language model in more detail.Unfortunately, the given portion of the document does not provide any information about whether the Boundless Distributed Alignment Search method can be used for large-scale genome sequencing projects or not. The text only focuses on the effectiveness of this method in scaling alignment search of causal structure in language models to billions of parameters and its potential in improving interpretability tools developed for language models. It also outlines the ability of Boundless DAS to find structure even when the model's task performance is low.\n",
              "\n",
              "Therefore, it is not possible to provide a definitive answer to this question based on the given text. There may be other parts of the document or other sources of information that could shed light on the applicability of this method to genome sequencing projects, but they are not included in the given portion of the text.Unfortunately, based on the provided portions of the document, it is not possible to determine how the Boundless Distributed Alignment Search method handles missing or incomplete data. The given sections only explain the general approach and effectiveness of the method in scaling alignment search and finding structure in language models. However, it is mentioned that future work needs to model errors of the language model in more detail, which could potentially include addressing missing or incomplete data. More information or context would be needed to provide a comprehensive answer to this question."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chcesz sprawdzić swoją wiedzę?:sure\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "1. What is the Boundless Distributed Alignment Search method and how does it work?\n",
              "a) The Boundless Distributed Alignment Search method is a technique used to align interpretable causal variables of a model C and fixed dimensionality linear subspaces of neural representations in a network N using gradient descent. It works by rotating neural representations in the network N with an orthogonal matrix to align with the interpretable causal variables of the model C.\n",
              "\n",
              "2. How does the Boundless Distributed Alignment Search method compare to other existing alignment search methods in terms of effectiveness and efficiency?\n",
              "a) Based on the given portion of the document, it is not possible to provide a detailed answer about how the Boundless Distributed Alignment Search method compares to other existing alignment search methods in terms of effectiveness and efficiency.\n",
              "\n",
              "3. What are the advantages and disadvantages of using the Boundless Distributed Alignment Search method?\n",
              "a) The advantages of using the Boundless Distributed Alignment Search method include its scalability, effectiveness in scaling alignment search of causal structure in Large Language Models (LLMs) to billions of parameters, and ability to identify ideal sets of hypotheses and search optimally. The disadvantages include only finding partial support for causal structure and requiring further research to model errors of the language model in more detail.\n",
              " \n",
              "4. Can the Boundless Distributed Alignment Search method be used for large-scale genome sequencing projects?\n",
              "a) Unfortunately, the given portion of the document does not provide any information about whether the Boundless Distributed Alignment Search method can be used for large-scale genome sequencing projects or not.\n",
              "\n",
              "5. How does the Boundless Distributed Alignment Search method handle missing or incomplete data?\n",
              "a) Based on the provided portions of the document, it is not possible to determine how the Boundless Distributed Alignment Search method handles missing or incomplete data. More information or context would be needed to provide a comprehensive answer to this question."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chcesz notatki?:yes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:695: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The Boundless Distributed Alignment Search (DAS) method is a powerful tool for aligning neural network representations with interpretable causal variables, allowing for better understanding and interpretation of the model. This technique works by rotating the neural representations in a network N with an orthogonal matrix to align with the interpretable causal variables of the model C using gradient descent.\n",
              "\n",
              "While it is not possible to determine how the Boundless DAS method compares to other existing alignment search methods in terms of effectiveness and efficiency based on the given portion of the document, it has several advantages and disadvantages. The Boundless DAS method can scale alignment search of causal structure in Large Language Models (LLMs) to billions of parameters, identify ideal sets of hypotheses, and search optimally. However, it may only find partial support for causal structure and requires further research to model errors of the language model in more detail.\n",
              "\n",
              "Furthermore, it is not possible to determine whether the Boundless Distributed Alignment Search method can be used for large-scale genome sequencing projects or how it handles missing or incomplete data based on the given portion of the document. However, the Boundless DAS method has been successfully used to align word embeddings with high-level concepts in Natural Language Processing (NLP) models.\n",
              "\n",
              "In summary, the Boundless Distributed Alignment Search method is a useful tool for aligning neural network representations with interpretable causal variables, allowing for better understanding and interpretation of the model. However, more information or context may be needed to provide a comprehensive answer to specific questions about its comparison to other methods, applicability to genome sequencing projects, and handling of missing or incomplete data."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chcesz pobrać:yes\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d92f01fc-baa0-452b-b131-777125608ede\", \"conversation.pdf\", 31741)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Conversation\n",
        "\n",
        "match chat_config.use_case:\n",
        "  case \"menu\":\n",
        "    #@markdown **Menu**\n",
        "    User_input = \"switch to compendium\" #@param {type:\"string\"}\n",
        "    chat_config.run(agent.run, User_input)\n",
        "\n",
        "  case \"compendium\":\n",
        "    #@markdown **Compendium:**\n",
        "    nazwa_kursu = \"-\" #@param [\"Fizyka I\", \"Analiza matematyczna\", \"-\"]\n",
        "    zakres = \"Boundless Distributed Alignment Search method and its effectiveness\" #@param {type:\"string\"}\n",
        "    literatura = \"https://arxiv.org/pdf/2305.08809.pdf\" #@param {type:\"string\"}\n",
        "    jezyk_literatury = \"eng\" #@param {type:\"string\"}\n",
        "\n",
        "    run_compendium(nazwa_kursu, zakres, literatura, jezyk_literatury)\n",
        "    chat_config.use_case = \"menu\" # powrot do menu\n",
        "\n",
        "  case \"img2pdf\":\n",
        "    #@markdown **ImgPDF:**\n",
        "    pdf_path = '' #@param {type:\"string\"}\n",
        "    return_path = '' #@param {type:\"string\"}\n",
        "\n",
        "    convert_images_to_searchable_pdf(pdf_path, return_path)\n",
        "    chat_config.use_case = \"menu\" # powrot do menu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xMczUL0DsTM5",
        "outputId": "e8dc8e49-e05a-48a2-f9b6-2198e013a3f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Used 14997 tokens, what cost: $0.029994'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title OpenAI api usage\n",
        "f\"Used {chat_config.used_tokens} tokens, what cost: ${chat_config.total_cost}\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
